{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from math import exp\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data file (insert your own path) Chage the path to the actual path of the file at the exam\n",
    "file_path = '/Users/balde/Desktop/Statestik/bmi1/bmi1_data.csv'\n",
    "\n",
    "# Load data\n",
    "D = pd.read_csv(file_path, sep=';')\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['LOG_DATA'] = np.log(D['DATA TO LOG TRANSFORM'])\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change LOG_DATA to the name you want your table to have, and DATA TO LOG TRANSFORM to the data from the data that should be log transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = np.random.normal(loc=50, scale=10, size=1000)  # Normal distribution data\n",
    "\n",
    "# Convert to a DataFrame for ease of use with Seaborn\n",
    "df = pd.DataFrame({'Value': data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = [1, 2, 4, 5, 6, 7, 8, 9, 10]  # Change this to the column you want to calculate the mean for\n",
    "mean_value = np.mean(value)\n",
    "print(f\"Mean: {mean_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 4, 5, 6, 7, 8, 9, 10]\n",
    "median = np.median(x)\n",
    "print(f\"Median: {median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "mode_result = mode(data, keepdims=True)  # keepdims ensures correct behavior in newer SciPy versions\n",
    "mode_value = mode_result.mode[0]\n",
    "print(f\"Mode: {mode_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "data_range = max(data) - min(data)\n",
    "print(f\"Range: {data_range}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "sample_variance = np.var(data, ddof=1)  # ddof=1 for sample variance\n",
    "print(f\"Sample Variance: {sample_variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "population_variance = np.var(data, ddof=0)\n",
    "print(f\"Population Variance: {population_variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance of discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "X = [0, 1, 2, 3, 4]  # possible values of X\n",
    "f_x = [0.17, 0.22, 0.28, 0, 0.33]  # probabilities of X\n",
    "mean_X = 2.10  # given mean\n",
    "# Calculate variance\n",
    "variance_X = sum([f_x[i] * (X[i] - mean_X)**2 for i in range(len(X))])\n",
    "print(\"Variance of X:\", variance_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Deviation (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "sample_std = np.std(data, ddof=1)  # ddof=1 for sample std\n",
    "print(f\"Sample Standard Deviation: {sample_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Deviation (Population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "Population_std = np.std(data, ddof=0)\n",
    "print(f\"Population Standard Deviation: {Population_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_first = 5                     # Sample size for first group\n",
    "df_for_single_sample = n_first - 1    # Degrees of freedom for single sample t-test\n",
    "\n",
    "n_second = 3                    # Sample size for second group\n",
    "df_for_two_sample = (n_first - 1) * (n_second - 1)  # if there is more than one sample (n-1)*(m-1)\n",
    "print(f\"Degrees of freedom for single sample t-test: {df_for_single_sample}\")\n",
    "print(f\"Degrees of freedom for two sample t-test: {df_for_two_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z-Score (Standard Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = 8\n",
    "mean = 4\n",
    "std_dev = 2\n",
    "z_score = (data_point - mean) / std_dev\n",
    "print(f\"z-Score: {z_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [4.8, 5.2, 4.9, 5.1, 5.3]\n",
    "population_mean = 5\n",
    "t_stat, p_value = ttest_1samp(data, population_mean)\n",
    "print(f\"t-Statistic: {t_stat}, p-value: {p_value}\")\n",
    "\n",
    "# ---------------------------------Or---------------------------------\n",
    "print()\n",
    "\n",
    "\n",
    "# Given values\n",
    "mu = 18  # Null hypothesis mean\n",
    "x_bar = 17  # Sample mean\n",
    "s = 4.5  # Sample standard deviation\n",
    "n = 48  # Sample size\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Calculate test statistic (t_obs)\n",
    "t_obs = (x_bar - mu) / (s / math.sqrt(n))\n",
    "\n",
    "# Calculate critical t-values for two-tailed test\n",
    "t_critical_lower = stats.t.ppf(alpha / 2, df)  # Lower critical value\n",
    "t_critical_upper = stats.t.ppf(1 - alpha / 2, df)  # Upper critical value\n",
    "\n",
    "# Output results\n",
    "print(\"Test Statistic (t_obs):\", t_obs)\n",
    "print(\"Critical Values (t_critical_lower, t_critical_upper):\", (t_critical_lower, t_critical_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "t_obs = -1.74\n",
    "n = 45\n",
    "alpha = 0.05\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Calculate p-value for two-tailed test\n",
    "p_value = 2 * t.cdf(t_obs, df)\n",
    "\n",
    "# Decision\n",
    "if p_value < alpha:\n",
    "    conclusion = \"Reject the null hypothesis (H0).\"\n",
    "else:\n",
    "    conclusion = \"Fail to reject the null hypothesis (H0).\"\n",
    "\n",
    "# Output\n",
    "print(f\"t-Statistic (t_obs): {t_obs}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "print(f\"Conclusion: {conclusion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "percentile_50 = np.percentile(data, 50)  # Median\n",
    "print(f\"50th Percentile (Median): {percentile_50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Error of the Mean (SEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_std = 2\n",
    "sem = sample_std / np.sqrt(len(data))\n",
    "print(f\"Standard Error of the Mean: {sem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margin of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEM needs to be run first\n",
    "z_star = 1.96  # For 95% confidence\n",
    "margin_of_error = z_star * sem\n",
    "print(f\"Margin of Error: {margin_of_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Average rate (λ) = 10, k = 15\n",
    "λ = 10\n",
    "k = 15\n",
    "poisson_prob = poisson.pmf(k, λ)\n",
    "print(f\"P(X = {k}) = {poisson_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: λ = 15/60 (15 cars/hour converted to minutes), t = 5\n",
    "λ = 15 / 60\n",
    "t = 5\n",
    "exp_prob = exp(-λ * t)\n",
    "print(f\"P(T > {t}) = {exp_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOVA (F-Statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Three groups of scores\n",
    "group1 = [88, 92, 85, 91]\n",
    "group2 = [76, 81, 77, 80]\n",
    "group3 = [90, 94, 92, 93]\n",
    "\n",
    "f_stat, p_value = f_oneway(group1, group2, group3)\n",
    "print(f\"F-statistic: {f_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Interval for Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: mean = 75, std = 10, n = 40, alpha = 0.05\n",
    "mean = 75\n",
    "std = 10\n",
    "n = 40\n",
    "alpha = 0.05\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "margin_error = t_critical * (std / np.sqrt(n))\n",
    "ci = (mean - margin_error, mean + margin_error)\n",
    "print(f\"Confidence Interval: {ci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Interval for STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "n = 48  # sample size\n",
    "s = 4.5  # sample standard deviation\n",
    "alpha = 0.05  # significance level\n",
    "df = n - 1  # degrees of freedom\n",
    "\n",
    "# Calculate chi-square critical values\n",
    "chi2_lower = stats.chi2.ppf(alpha / 2, df)  # lower critical value\n",
    "chi2_upper = stats.chi2.ppf(1 - alpha / 2, df)  # upper critical value\n",
    "\n",
    "# Confidence interval for standard deviation\n",
    "std_lower = np.sqrt((df * s**2) / chi2_upper)  # lower bound\n",
    "std_upper = np.sqrt((df * s**2) / chi2_lower)  # upper bound\n",
    "std_lower, std_upper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = [10, 12, 9, 11, 8, 10]  # Observed counts\n",
    "expected = [10] * len(observed)  # Equal expected counts\n",
    "chi2_stat, p_value, _, _ = chi2_contingency([observed, expected])\n",
    "print(f\"Chi-squared statistic: {chi2_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected count. Chi-Squared Test for independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding an expected value of a cell in a contingency table. \n",
    "row_total = 100\n",
    "column_total = 50\n",
    "grand_total = 200\n",
    "expected = (row_total * column_total) / grand_total\n",
    "print(f\"Expected value: {expected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Batch sizes and costs\n",
    "batch_sizes = [50, 100, 150, 200, 250]\n",
    "costs = [2.33, 4.21, 6.01, 7.51, 8.46]\n",
    "\n",
    "X = sm.add_constant(batch_sizes)  # Add intercept\n",
    "model = sm.OLS(costs, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Linear Regression Model Output\n",
    "r_squared = model.rsquared\n",
    "print(f\"R-squared: {r_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Error in Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct calculation of standard error\n",
    "std_error = std / np.sqrt(n)\n",
    "print(f\"Standard Error: {std_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: n = 5, p = 0.5, k = 3\n",
    "n = 5       # Number of trials\n",
    "p = 0.5     # Probability of success\n",
    "k = 3       # Desired number of successes\n",
    "binomial_prob = binom.pmf(k, n, p)\n",
    "print(f\"P(X = {k}) = {binomial_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: K = x^2 + y, variances σx = 1, σy = 0.5\n",
    "x = 2\n",
    "y = 3\n",
    "σx = 1\n",
    "σy = 0.5\n",
    "\n",
    "dK_dx = 2 * x\n",
    "dK_dy = 1\n",
    "\n",
    "variance_K = (dK_dx**2 * σx**2) + (dK_dy**2 * σy**2)\n",
    "print(f\"Variance of K: {variance_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Sample z-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [50, 52, 48, 49, 51]\n",
    "mu_0 = 50  # Hypothesized mean\n",
    "sigma = 2  # Population standard deviation\n",
    "n = len(data)\n",
    "\n",
    "# Calculate sample mean\n",
    "sample_mean = np.mean(data)\n",
    "\n",
    "# Calculate z-statistic\n",
    "z_stat = (sample_mean - mu_0) / (sigma / np.sqrt(n))\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = 2 * (1 - norm.cdf(abs(z_stat)))  # Two-tailed test\n",
    "print(f\"z-Statistic: {z_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Sample t-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [50, 52, 48, 49, 51]\n",
    "mu_0 = 50  # Hypothesized mean\n",
    "\n",
    "# Perform one-sample t-test\n",
    "t_stat, p_value = ttest_1samp(data, mu_0)\n",
    "print(f\"t-Statistic: {t_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paired t-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Before and after scores\n",
    "before = [85, 89, 93, 88, 91]\n",
    "after = [86, 90, 92, 87, 89]\n",
    "\n",
    "t_stat, p_value = ttest_rel(before, after)\n",
    "print(f\"Paired t-test: t-statistic = {t_stat}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-Sample t-Test (Independent Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = [50, 52, 48, 49, 51]\n",
    "group2 = [45, 47, 46, 44, 46]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_value = ttest_ind(group1, group2)\n",
    "print(f\"t-Statistic: {t_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Dataset\n",
    "data = [1, 2, 3, 4, 5]\n",
    "n_iterations = 1000\n",
    "bootstrap_samples = [np.mean(np.random.choice(data, size=len(data), replace=True)) for _ in range(n_iterations)]\n",
    "ci = np.percentile(bootstrap_samples, [2.5, 97.5])\n",
    "print(f\"Bootstrap Confidence Interval: {ci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Value'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram of Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Box Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(x=df['Value'])\n",
    "plt.title('Box Plot of Values')\n",
    "plt.xlabel('Value')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
