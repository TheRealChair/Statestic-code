{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from math import exp\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data file (insert your own path) Chage the path to the actual path of the file at the exam\n",
    "file_path = '/Users/balde/Desktop/Statestik/bmi1/bmi1_data.csv'\n",
    "\n",
    "# Load data\n",
    "D = pd.read_csv(file_path, sep=';')\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['LOG_DATA'] = np.log(D['DATA TO LOG TRANSFORM'])\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change LOG_DATA to the name you want your table to have, and DATA TO LOG TRANSFORM to the data from the data that should be log transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = np.random.normal(loc=50, scale=10, size=1000)  # Normal distribution data\n",
    "\n",
    "# Convert to a DataFrame for ease of use with Seaborn\n",
    "df = pd.DataFrame({'Value': data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = [1, 2, 4, 5, 6, 7, 8, 9, 10]  # Change this to the column you want to calculate the mean for\n",
    "mean_value = np.mean(value)\n",
    "print(f\"Mean: {mean_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 4, 5, 6, 7, 8, 9, 10]\n",
    "median = np.median(x)\n",
    "print(f\"Median: {median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "mode_result = mode(data, keepdims=True)  # keepdims ensures correct behavior in newer SciPy versions\n",
    "mode_value = mode_result.mode[0]\n",
    "print(f\"Mode: {mode_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "data_range = max(data) - min(data)\n",
    "print(f\"Range: {data_range}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "sample_variance = np.var(data, ddof=1)  # ddof=1 for sample variance\n",
    "print(f\"Sample Variance: {sample_variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "population_variance = np.var(data, ddof=0)\n",
    "print(f\"Population Variance: {population_variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance of discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "X = [0, 1, 2, 3, 4]  # possible values of X\n",
    "f_x = [0.17, 0.22, 0.28, 0, 0.33]  # probabilities of X\n",
    "mean_X = 2.10  # given mean\n",
    "# Calculate variance\n",
    "variance_X = sum([f_x[i] * (X[i] - mean_X)**2 for i in range(len(X))])\n",
    "print(\"Variance of X:\", variance_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Deviation (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "sample_std = np.std(data, ddof=1)  # ddof=1 for sample std\n",
    "print(f\"Sample Standard Deviation: {sample_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Deviation (Population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "Population_std = np.std(data, ddof=0)\n",
    "print(f\"Population Standard Deviation: {Population_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_first = 5                     # Sample size for first group\n",
    "df_for_single_sample = n_first - 1    # Degrees of freedom for single sample t-test\n",
    "\n",
    "n_second = 3                    # Sample size for second group\n",
    "df_for_two_sample = (n_first - 1) * (n_second - 1)  # if there is more than one sample (n-1)*(m-1)\n",
    "print(f\"Degrees of freedom for single sample t-test: {df_for_single_sample}\")\n",
    "print(f\"Degrees of freedom for two sample t-test: {df_for_two_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z-Score (Standard Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = 8\n",
    "mean = 4\n",
    "std_dev = 2\n",
    "z_score = (data_point - mean) / std_dev\n",
    "print(f\"z-Score: {z_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [4.8, 5.2, 4.9, 5.1, 5.3]\n",
    "population_mean = 5\n",
    "t_stat, p_value = ttest_1samp(data, population_mean)\n",
    "print(f\"t-Statistic: {t_stat}, p-value: {p_value}\")\n",
    "\n",
    "# ---------------------------------Or---------------------------------\n",
    "print()\n",
    "\n",
    "\n",
    "# Given values\n",
    "mu = 18  # Null hypothesis mean\n",
    "x_bar = 17  # Sample mean\n",
    "s = 4.5  # Sample standard deviation\n",
    "n = 48  # Sample size\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Calculate test statistic (t_obs)\n",
    "t_obs = (x_bar - mu) / (s / math.sqrt(n))\n",
    "\n",
    "# Calculate critical t-values for two-tailed test\n",
    "t_critical_lower = stats.t.ppf(alpha / 2, df)  # Lower critical value\n",
    "t_critical_upper = stats.t.ppf(1 - alpha / 2, df)  # Upper critical value\n",
    "\n",
    "# Output results\n",
    "print(\"Test Statistic (t_obs):\", t_obs)\n",
    "print(\"Critical Values (t_critical_lower, t_critical_upper):\", (t_critical_lower, t_critical_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "t_obs = -1.74\n",
    "n = 45\n",
    "alpha = 0.05\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Calculate p-value for two-tailed test\n",
    "p_value = 2 * t.cdf(t_obs, df)\n",
    "# p_value = t.cdf(t_obs, df) # Example: Left-tailed test\n",
    "# p_value = 1 - t.cdf(t_obs, df) # Example: Right-tailed test\n",
    "\n",
    "# Decision\n",
    "if p_value < alpha:\n",
    "    conclusion = \"Reject the null hypothesis (H0).\"\n",
    "else:\n",
    "    conclusion = \"Fail to reject the null hypothesis (H0).\"\n",
    "\n",
    "# Output\n",
    "print(f\"t-Statistic (t_obs): {t_obs}\")\n",
    "print(f\"Degrees of Freedom: {df}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "print(f\"Conclusion: {conclusion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 2, 3, 4]\n",
    "percentile_50 = np.percentile(data, 50)  # Median\n",
    "print(f\"50th Percentile (Median): {percentile_50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Error of the Mean (SEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_std = 2\n",
    "sem = sample_std / np.sqrt(len(data))\n",
    "print(f\"Standard Error of the Mean: {sem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margin of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEM needs to be run first\n",
    "z_star = 1.96  # For 95% confidence\n",
    "margin_of_error = z_star * sem\n",
    "print(f\"Margin of Error: {margin_of_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Average rate (λ) = 10, k = 15\n",
    "λ = 10\n",
    "k = 15\n",
    "poisson_prob = poisson.pmf(k, λ)\n",
    "print(f\"P(X = {k}) = {poisson_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: λ = 15/60 (15 cars/hour converted to minutes), t = 5\n",
    "λ = 15 / 60\n",
    "t = 5\n",
    "exp_prob = exp(-λ * t)\n",
    "print(f\"P(T > {t}) = {exp_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOVA (F-Statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Three groups of scores\n",
    "group1 = [88, 92, 85, 91]\n",
    "group2 = [76, 81, 77, 80]\n",
    "group3 = [90, 94, 92, 93]\n",
    "\n",
    "f_stat, p_value = f_oneway(group1, group2, group3)\n",
    "print(f\"F-statistic: {f_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Interval for Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: mean = 75, std = 10, n = 40, alpha = 0.05\n",
    "mean = 75\n",
    "std = 10\n",
    "n = 40\n",
    "alpha = 0.05\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "margin_error = t_critical * (std / np.sqrt(n))\n",
    "ci = (mean - margin_error, mean + margin_error)\n",
    "print(f\"Confidence Interval: {ci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Interval for STD (sample standard deviation) chi squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "n = 48  # sample size\n",
    "s = 4.5  # sample standard deviation\n",
    "alpha = 0.05  # significance level\n",
    "df = n - 1  # degrees of freedom\n",
    "\n",
    "# Calculate chi-square critical values\n",
    "chi2_lower = stats.chi2.ppf(alpha / 2, df)  # lower critical value\n",
    "chi2_upper = stats.chi2.ppf(1 - alpha / 2, df)  # upper critical value\n",
    "\n",
    "# Confidence interval for standard deviation\n",
    "std_lower = np.sqrt((df * s**2) / chi2_upper)  # lower bound\n",
    "std_upper = np.sqrt((df * s**2) / chi2_lower)  # upper bound\n",
    "std_lower, std_upper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals for proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [0.303, 0.342]\n",
      "Test statistic (z): -0.58\n",
      "P-value: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "survivors = 709\n",
    "total_passengers = 2201\n",
    "z = 1.96  # Z-value for 95% confidence level\n",
    "\n",
    "# Sample proportion\n",
    "p_hat = survivors / total_passengers\n",
    "\n",
    "# Standard error\n",
    "se = math.sqrt(p_hat * (1 - p_hat) / total_passengers)\n",
    "\n",
    "# Margin of error\n",
    "margin_of_error = z * se\n",
    "\n",
    "# Confidence interval\n",
    "lower_bound = p_hat - margin_of_error\n",
    "upper_bound = p_hat + margin_of_error\n",
    "\n",
    "print(f\"95% Confidence Interval: [{lower_bound:.3f}, {upper_bound:.3f}]\")\n",
    "\n",
    "#_______________________________________________________\n",
    "#statistical difference between two groups in probability of survival\n",
    "# Given data\n",
    "survivors_crew = 212\n",
    "total_crew = 885\n",
    "survivors_3rd = 178\n",
    "total_3rd = 706\n",
    "\n",
    "# Proportions\n",
    "p_crew = survivors_crew / total_crew\n",
    "p_3rd = survivors_3rd / total_3rd\n",
    "\n",
    "# Pooled proportion\n",
    "p_pooled = (survivors_crew + survivors_3rd) / (total_crew + total_3rd)\n",
    "\n",
    "# Standard error\n",
    "se = math.sqrt(p_pooled * (1 - p_pooled) * (1 / total_crew + 1 / total_3rd))\n",
    "\n",
    "# Test statistic\n",
    "z = (p_crew - p_3rd) / se\n",
    "\n",
    "# P-value\n",
    "p_value = 2 * norm.sf(abs(z))\n",
    "\n",
    "# Output results\n",
    "print(f\"Test statistic (z): {z:.2f}\")\n",
    "print(f\"P-value: {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = [10, 12, 9, 11, 8, 10]  # Observed counts\n",
    "expected = [10] * len(observed)  # Equal expected counts\n",
    "chi2_stat, p_value, _, _ = chi2_contingency([observed, expected])\n",
    "print(f\"Chi-squared statistic: {chi2_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected count. Chi-Squared Test for independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding an expected value of a cell in a contingency table. \n",
    "row_total = 100\n",
    "column_total = 50\n",
    "grand_total = 200\n",
    "expected = (row_total * column_total) / grand_total\n",
    "print(f\"Expected value: {expected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-squared statistic  / critcal value\n",
    "\n",
    "Calculated from a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, chi2\n",
    "\n",
    "# Given data\n",
    "s = np.array([202, 117, 178, 212])  # Observed survivors\n",
    "n = np.array([325, 285, 706, 885])  # Total passengers\n",
    "tab = np.array([s, n - s])  # Construct the contingency table\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(tab)\n",
    "\n",
    "# Output the test statistics\n",
    "print(f\"Chi-squared statistic (X-squared): {chi2_stat:.2f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"P-value: {p_value:.4e}\")\n",
    "\n",
    "# Calculate the critical value for alpha = 0.95 and df = 3\n",
    "critical_value = chi2.ppf(0.95, df=dof)\n",
    "print(f\"Critical value: {critical_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-sample porportions test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Given data\n",
    "s = np.array([202, 117, 178, 212])  # Number of survivors\n",
    "n = np.array([325, 285, 706, 885])  # Total number of passengers\n",
    "\n",
    "# Proportions for group 1 and group 2\n",
    "p1 = s[0] / n[0]  # Proportion for group 1 (first class)\n",
    "p2 = np.sum(s[1:]) / np.sum(n[1:])  # Proportion for other groups (2nd, 3rd, and Crew)\n",
    "\n",
    "# Group sizes for n1 and n2\n",
    "n1 = np.sum(n[0:1])  # Total for group 1 (first class)\n",
    "n2 = np.sum(n[1:])  # Total for other groups (2nd, 3rd, and Crew)\n",
    "\n",
    "# Overall proportion\n",
    "ph = np.sum(s) / np.sum(n)\n",
    "\n",
    "# Calculate the confidence interval for the difference between p1 and p2\n",
    "z_score = norm.ppf(0.975)  # 95% confidence interval\n",
    "ci_lower = p1 - p2 - z_score * np.sqrt(p1 * (1 - p1) / n1 + p2 * (1 - p2) / n2)\n",
    "ci_upper = p1 - p2 + z_score * np.sqrt(p1 * (1 - p1) / n1 + p2 * (1 - p2) / n2)\n",
    "\n",
    "print(f\"Confidence Interval for the difference in proportions: ({ci_lower:.6f}, {ci_upper:.6f})\")\n",
    "\n",
    "# 2-sample proportion test without continuity correction\n",
    "count = np.array([202, np.sum(s[1:])])  # Survivors in each group\n",
    "n_total = np.array([325, np.sum(n[1:])])  # Total in each group\n",
    "\n",
    "# Perform the two-sample proportion test\n",
    "stat, p_value = proportions_ztest(count, n_total, alternative='two-sided')\n",
    "\n",
    "print(f\"Two-sample proportion test statistics: {stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Batch sizes and costs\n",
    "batch_sizes = [50, 100, 150, 200, 250]\n",
    "costs = [2.33, 4.21, 6.01, 7.51, 8.46]\n",
    "\n",
    "X = sm.add_constant(batch_sizes)  # Add intercept\n",
    "model = sm.OLS(costs, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Linear Regression Model Output\n",
    "r_squared = model.rsquared\n",
    "print(f\"R-squared: {r_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Error in Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct calculation of standard error\n",
    "std_error = std / np.sqrt(n)\n",
    "print(f\"Standard Error: {std_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: n = 5, p = 0.5, k = 3\n",
    "n = 5       # Number of trials\n",
    "p = 0.5     # Probability of success\n",
    "k = 3       # Desired number of successes\n",
    "binomial_prob = binom.pmf(k, n, p)\n",
    "print(f\"P(X = {k}) = {binomial_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: K = x^2 + y, variances σx = 1, σy = 0.5\n",
    "x = 2\n",
    "y = 3\n",
    "σx = 1\n",
    "σy = 0.5\n",
    "\n",
    "dK_dx = 2 * x\n",
    "dK_dy = 1\n",
    "\n",
    "variance_K = (dK_dx**2 * σx**2) + (dK_dy**2 * σy**2)\n",
    "print(f\"Variance of K: {variance_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Sample z-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [50, 52, 48, 49, 51]\n",
    "mu_0 = 50  # Hypothesized mean\n",
    "sigma = 2  # Population standard deviation\n",
    "n = len(data)\n",
    "\n",
    "# Calculate sample mean\n",
    "sample_mean = np.mean(data)\n",
    "\n",
    "# Calculate z-statistic\n",
    "z_stat = (sample_mean - mu_0) / (sigma / np.sqrt(n))\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = 2 * (1 - norm.cdf(abs(z_stat)))  # Two-tailed test\n",
    "print(f\"z-Statistic: {z_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Sample t-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [50, 52, 48, 49, 51]\n",
    "mu_0 = 50  # Hypothesized mean\n",
    "\n",
    "# Perform one-sample t-test\n",
    "t_stat, p_value = ttest_1samp(data, mu_0)\n",
    "print(f\"t-Statistic: {t_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paired t-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Before and after scores\n",
    "before = [85, 89, 93, 88, 91]\n",
    "after = [86, 90, 92, 87, 89]\n",
    "\n",
    "t_stat, p_value = ttest_rel(before, after)\n",
    "print(f\"Paired t-test: t-statistic = {t_stat}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-Sample t-Test (Independent Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = [50, 52, 48, 49, 51]\n",
    "group2 = [45, 47, 46, 44, 46]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_value = ttest_ind(group1, group2)\n",
    "print(f\"t-Statistic: {t_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Dataset\n",
    "data = [1, 2, 3, 4, 5]\n",
    "n_iterations = 1000\n",
    "bootstrap_samples = [np.mean(np.random.choice(data, size=len(data), replace=True)) for _ in range(n_iterations)]\n",
    "ci = np.percentile(bootstrap_samples, [2.5, 97.5])\n",
    "print(f\"Bootstrap Confidence Interval: {ci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Standard Deviation: 6.027\n"
     ]
    }
   ],
   "source": [
    "# Given values\n",
    "SST = 915.92  # Total sum of squares\n",
    "SS_location = 480.00  # Sum of squares for location\n",
    "total_observations = 16  # total obs on the table\n",
    "number_of_groups = 4  # 4 locations\n",
    "\n",
    "# Calculate SSE (Residual sum of squares)\n",
    "SSE = SST - SS_location\n",
    "\n",
    "# Calculate degrees of freedom for error\n",
    "df_error = total_observations - number_of_groups\n",
    "\n",
    "# Calculate error standard deviation\n",
    "error_std = np.sqrt(SSE / df_error)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Error Standard Deviation: {error_std:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Value'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram of Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Box Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(x=df['Value'])\n",
    "plt.title('Box Plot of Values')\n",
    "plt.xlabel('Value')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson distributions basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda (Rate): 2.5\n",
      "Variance: 2.5\n",
      "Standard Deviation: 1.581\n",
      "Mode (Most Probable Value): 2\n",
      "P(X = 5) = 0.0668\n",
      "P(X ≤ 5) = 0.9580\n",
      "P(X > 5) = 0.0420\n",
      "P(X = 0) = 0.0821\n",
      "Simulated Events: [2 5 4 0 2 1 2 6 4 1]\n",
      "Total Expected Events Over 7 Days: 17.5\n",
      "95% Confidence Interval for λ: [12, 29]\n",
      "75th Percentile: 3.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Key Parameter: λ (Rate of Events)\n",
    "lambda_ = 2.5  # Average number of events per unit time\n",
    "\n",
    "# 2. Basic Properties\n",
    "variance = lambda_  # Variance of Poisson\n",
    "std_dev = np.sqrt(lambda_)  # Standard deviation of Poisson\n",
    "mode = int(lambda_)  # Most probable number of events (mode)\n",
    "\n",
    "print(f\"Lambda (Rate): {lambda_}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Standard Deviation: {std_dev:.3f}\")\n",
    "print(f\"Mode (Most Probable Value): {mode}\")\n",
    "\n",
    "# 3. Exact Probability (PMF)\n",
    "k_exact = 5  # Example: Probability of exactly 5 events\n",
    "prob_exact = poisson.pmf(k_exact, lambda_)\n",
    "print(f\"P(X = {k_exact}) = {prob_exact:.4f}\")\n",
    "\n",
    "# 4. Cumulative Probability (CDF)\n",
    "k_cumulative = 5  # Example: Probability of 5 or fewer events\n",
    "prob_cumulative = poisson.cdf(k_cumulative, lambda_)\n",
    "print(f\"P(X ≤ {k_cumulative}) = {prob_cumulative:.4f}\")\n",
    "\n",
    "# 5. Complement Probability\n",
    "prob_at_least = 1 - prob_cumulative  # Probability of 6 or more events\n",
    "print(f\"P(X > {k_cumulative}) = {prob_at_least:.4f}\")\n",
    "\n",
    "# 6. Probability of No Events (Special Case)\n",
    "prob_no_events = math.exp(-lambda_)  # P(X = 0)\n",
    "print(f\"P(X = 0) = {prob_no_events:.4f}\")\n",
    "\n",
    "# 7. Simulation of Poisson Events\n",
    "simulated_events = np.random.poisson(lambda_, size=10)  # Simulate 10 events\n",
    "print(f\"Simulated Events: {simulated_events}\")\n",
    "\n",
    "# 8. Scaling Over Time\n",
    "days = 7  # Number of time units (e.g., days)\n",
    "lambda_total = lambda_ * days  # Total mean over 7 days\n",
    "print(f\"Total Expected Events Over {days} Days: {lambda_total}\")\n",
    "\n",
    "# 9. Confidence Intervals for Observed Data\n",
    "observed_fires = 20  # Example observed events in a given time period\n",
    "confidence_level = 0.95  # 95% confidence interval\n",
    "lower = poisson.ppf((1 - confidence_level) / 2, observed_fires)\n",
    "upper = poisson.ppf(1 - (1 - confidence_level) / 2, observed_fires)\n",
    "print(f\"95% Confidence Interval for λ: [{lower:.0f}, {upper:.0f}]\")\n",
    "\n",
    "# 10. Percentile Calculation\n",
    "percentile = 0.75  # 75th percentile\n",
    "k_percentile = poisson.ppf(percentile, lambda_)\n",
    "print(f\"75th Percentile: {k_percentile}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
