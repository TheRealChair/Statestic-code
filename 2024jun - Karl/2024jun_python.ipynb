{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from math import exp\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Poisson Distribution Problem: Counting Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Description**\n",
    "\n",
    "Two students are counting cars on two roads, assuming Poisson distributions:\n",
    "- **Road 1**: Expected rate $ \\lambda_1 = 10 $ cars/hour.\n",
    "- **Road 2**: Expected rate $ \\lambda_2 = 15 $ cars/hour.\n",
    "\n",
    "**Question**\n",
    "\n",
    "Find the probability $ P(X_1 = 10) $, where $ X_1 $ is the number of cars passing on Road 1 in 15 minutes.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "We use the **PMF** (non-cumulative) here because we are calculating the probability of a specific outcome \\( X = y \\). \n",
    "The PMF provides the exact probability of observing this specific value, unlike the **PPF**, \n",
    "which is used to determine thresholds or quantiles for cumulative probabilities P\\(x \\< k\\).\n",
    "\n",
    "1. Adjust $ \\lambda_1 $ for 15 minutes:\n",
    "   $$\n",
    "   \\lambda_{15} = 10 \\times \\frac{15}{60} = 2.5\n",
    "   $$\n",
    "2. Use the Poisson PMF formula:\n",
    "   $$\n",
    "   P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "   $$\n",
    "   For $ k = 10 $ and $ \\lambda = 2.5 $:\n",
    "   $$\n",
    "   P(X_1 = 10) = \\frac{2.5^{10} e^{-2.5}}{10!}\n",
    "   $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X_1 = 10) = nan\n"
     ]
    }
   ],
   "source": [
    "lambda_15 = 2.5  # Expected number of cars in 15 minutes\n",
    "k = 10  # Desired number of cars\n",
    "\n",
    "# Calculate probability using scipy's poisson PMF\n",
    "poisson_prob = stats.poisson.pmf(k, lambda_15)\n",
    "\n",
    "print(f\"P(X_1 = 10) = {poisson_prob:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 $ \\frac{E[X_1]}{E[X_2]} = 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Description**\n",
    "\n",
    "Two students are counting the number of cars passing by on two roads, assuming Poisson distributions:\n",
    "- **Road 1**: Expected rate $ \\lambda_1 = 10 $ cars/hour.\n",
    "- **Road 2**: Expected rate $ \\lambda_2 = 15 $ cars/hour.\n",
    "\n",
    "They define two random variables:\n",
    "- $ X_1 $: The number of cars passing on road 1 in 15 minutes.\n",
    "- $ X_2 $: The number of cars passing on road 2 in 10 minutes.\n",
    "\n",
    "**Question**\n",
    "\n",
    "Which of the following statements about the ratio of the expected values of $ X_1 $ and $ X_2 $ is correct?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. Calculate $ E[X_1] $:  \n",
    "   Adjust $ \\lambda_1 $ for 15 minutes:  \n",
    "   $$\n",
    "   \\lambda_{X_1} = \\lambda_1 \\cdot \\frac{15}{60} = 10 \\cdot 0.25 = 2.5\n",
    "   $$  \n",
    "   Therefore, $ E[X_1] = 2.5 $.\n",
    "\n",
    "2. Calculate $ E[X_2] $:  \n",
    "   Adjust $ \\lambda_2 $ for 10 minutes:  \n",
    "   $$\n",
    "   \\lambda_{X_2} = \\lambda_2 \\cdot \\frac{10}{60} = 15 \\cdot \\frac{1}{6} = 2.5\n",
    "   $$  \n",
    "   Therefore, $ E[X_2] = 2.5 $.\n",
    "\n",
    "3. Calculate the ratio:  \n",
    "   $$\n",
    "   \\frac{E[X_1]}{E[X_2]} = \\frac{2.5}{2.5} = 1\n",
    "   $$\n",
    "\n",
    "**Answer**\n",
    "\n",
    "The correct statement is:  \n",
    "**5.** $ \\frac{E[X_1]}{E[X_2]} = 1 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 What is the probability that the time between two cars passing by is greater than 2 minutes on road 2?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate (cars per minute): 0.25\n",
      "Method 1 - Using the formula: P(T > 2) = 0.606531\n",
      "Method 2 - Using scipy.stats.sf: P(T > 2) = 0.606531\n",
      "Method 3 - Using CDF complement: P(T > 2) = 0.606531\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Given data\n",
    "lambda_per_hour = 15  # Cars per hour on road 2\n",
    "\n",
    "# Convert cars per hour to cars per minute\n",
    "rate_per_minute = lambda_per_hour / 60  # Cars per minute\n",
    "print(f\"Rate (cars per minute): {rate_per_minute:.2f}\")\n",
    "\n",
    "# Time interval\n",
    "time = 2  # Time in minutes\n",
    "\n",
    "# multiple methods to calculate the probability\n",
    "# Method 1: Using the Exponential Formula\n",
    "probability_formula = np.exp(-rate_per_minute * time)\n",
    "print(f\"Method 1 - Using the formula: P(T > 2) = {probability_formula:.6f}\")\n",
    "\n",
    "# Method 2: Using scipy.stats.expon Survival Function (sf)\n",
    "probability_sf = stats.expon.sf(time, scale=1/rate_per_minute)\n",
    "print(f\"Method 2 - Using scipy.stats.sf: P(T > 2) = {probability_sf:.6f}\")\n",
    "\n",
    "# Method 3: Using scipy.stats.expon CDF and complement\n",
    "probability_cdf_complement = 1 - stats.expon.cdf(time, scale=1/rate_per_minute)\n",
    "print(f\"Method 3 - Using CDF complement: P(T > 2) = {probability_cdf_complement:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A farm made a study in which 225 chickens were randomly divided into 3 treatment groups\n",
    "of 75 animals each. Each group were fed with fodder from different feed producers during a\n",
    "period. For each chicken the weight change over the period of time was measured and the\n",
    "final data set consists of 225 observations of weight changes. The objective of the study is to\n",
    "determine if there is statistical evidence for difference in mean weight change for at least one\n",
    "of the groups. It may be assumed that the variance is the same in all treatment groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 What kind of statistical analysis is most suitable for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-way analysis of variance (one way ANOVA)**\n",
    "\n",
    "**Variables**: ANOVA is ideal because the independent variable is categorical (three feed producers), and the dependent variable is continuous (weight change).\n",
    "\n",
    "**Number of Groups**: With three groups, ANOVA avoids the inflated error rates that would occur with multiple t-tests.\n",
    "\n",
    "**Objective**: The study aims to compare mean differences among the groups, which is the primary purpose of ANOVA. Other methods are designed for different data structures or goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The engineers at an international airport have conducted a survey, in which they have timed 40\n",
    "randomly selected security checks. The average duration of the security checks included in the\n",
    "survey was 34.66 seconds, and the sample standard deviation was 10.12 seconds, it is assumed\n",
    "that the times are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 99% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-value: 2.707913\n",
      "Margin of Error: 4.332966\n",
      "Confidence Interval: (30.327034, 38.992966)\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "mean = 34.66\n",
    "std_dev = 10.12\n",
    "n = 40\n",
    "confidence_level = 0.99\n",
    "\n",
    "# Calculate the t-value\n",
    "t_value = stats.t.ppf((1 + confidence_level) / 2, df=n-1)\n",
    "print(f\"t-value: {t_value:.6f}\")\n",
    "\n",
    "# Margin of error\n",
    "margin_of_error = t_value * (std_dev / (n ** 0.5))\n",
    "print(f\"Margin of Error: {margin_of_error:.6f}\")\n",
    "\n",
    "# Confidence interval\n",
    "lower_bound = mean - margin_of_error\n",
    "upper_bound = mean + margin_of_error\n",
    "\n",
    "print(f\"Confidence Interval: ({lower_bound:.6f}, {upper_bound:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 p-value two sided alternative hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 2.912295\n",
      "p-value: 0.005908\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "mean = 34.66\n",
    "hypothesized_mean = 30\n",
    "std_dev = 10.12\n",
    "n = 40\n",
    "\n",
    "# Compute the t-statistic\n",
    "t_stat = (mean - hypothesized_mean) / (std_dev / (n ** 0.5))\n",
    "\n",
    "# Compute the two-tailed p-value\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))\n",
    "\n",
    "print(f\"t-statistic: {t_stat:.6f}\")\n",
    "print(f\"p-value: {p_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model for Cost Analysis\n",
    "\n",
    "The engineers initially believe that the data can be described by a **linear model** of the form:\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad i \\in \\{1, \\dots, 10\\},\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\epsilon_i$ are independent and identically distributed (i.i.d.) random errors, following a normal distribution:  \n",
    "  $$\n",
    "  \\epsilon_i \\sim N(0, \\sigma^2)\n",
    "  $$\n",
    "- The response variable ($Y_i$) represents the **cost** (in million DKK).\n",
    "- The explanatory variable ($x_i$) represents the **batch size** (in units).\n",
    "\n",
    "The engineers fit this **linear regression model** using the **least squares method**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 What proportion of the variation in the costs is explained by the regression model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Costs   R-squared:                       0.906\n",
      "Model:                            OLS   Adj. R-squared:                  0.894\n",
      "Method:                 Least Squares   F-statistic:                     77.07\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           2.22e-05\n",
      "Time:                        09:27:43   Log-Likelihood:                -12.449\n",
      "No. Observations:                  10   AIC:                             28.90\n",
      "Df Residuals:                       8   BIC:                             29.50\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.8953      0.642      4.512      0.002       1.415       4.375\n",
      "Batch          0.0182      0.002      8.779      0.000       0.013       0.023\n",
      "==============================================================================\n",
      "Omnibus:                        1.298   Durbin-Watson:                   0.593\n",
      "Prob(Omnibus):                  0.523   Jarque-Bera (JB):                0.906\n",
      "Skew:                          -0.487   Prob(JB):                        0.636\n",
      "Kurtosis:                       1.893   Cond. No.                         670.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karl_\\Miniconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:418: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=10 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create the dataset\n",
    "# Batch size is the independent variable, and Costs is the dependent variable\n",
    "data = {\n",
    "    \"Batch\": [50, 100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
    "    \"Costs\": [2.33, 4.21, 6.01, 7.51, 8.46, 8.93, 9.45, 10.70, 10.55, 10.74]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Prepare variables\n",
    "X = sm.add_constant(df[\"Batch\"])  # Add intercept to the independent variable (B0)\n",
    "y = df[\"Costs\"]  # Dependent variable\n",
    "\n",
    "# Step 3: Fit the regression model\n",
    "fit = sm.OLS(y, X).fit()  # Ordinary Least Squares regression\n",
    "\n",
    "# Step 4: Display the summary\n",
    "print(fit.summary())\n",
    "\n",
    "# Output:\n",
    "# - Coefficients: Intercept and slope of the regression line\n",
    "# - R-squared: Proportion of variance in Costs explained by Batch\n",
    "# - P-values: Test significance of the coefficients\n",
    "# - F-statistic: Significance of the overall model\n",
    "\n",
    "\n",
    "# R-sqaured is correct here!!!\n",
    "\n",
    "# Use normal R-squared for simple regression!!\n",
    "# Use adjusted R-squared for multiple regression!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Confidence interval of slope B_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% Confidence interval for the slope (Î²1): \n",
      "              0         1\n",
      "const  0.742056  5.048611\n",
      "Batch  0.011218  0.025099\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Fit the regression model\n",
    "fit = sm.OLS(y, X).fit()\n",
    "\n",
    "# Step 4: Extract 99% confidence interval for coefficients\n",
    "coeff_conf_int_99 = fit.conf_int(alpha=0.01)  # 99% confidence interval\n",
    "slope_conf_int_99 = coeff_conf_int_99.loc[\"Batch\"]  # Confidence interval for beta_1 (slope)\n",
    "\n",
    "# Just focus on Batch, as that is beta_1 (slope) the !!explanatory variable!!!\n",
    "print(\"Confindence Interval for Slope (99%):\")\n",
    "print(coeff_conf_int_99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of persons living in Danish dorms in 2023 is provided by Statistics Denmark. Here\n",
    "we focus only on a few age-categories:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 What proportion of the residents of Danish dormitories are males (among the 18-39 year olds)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage is: 53.70%\n"
     ]
    }
   ],
   "source": [
    "# easy simple calculation\n",
    "\n",
    "males = 24998/ 46551\n",
    "\n",
    "print(\"Percentage is: {males:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 We would like to know whether the proportions of males in different age-groups is significantly different (using a 5% significance level). Which of the following statements is true?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if male proportions differ across age groups, we use the chi-squared test, which is suitable for categorical data. ${x**2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of freedom: 2\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate the number of degrees of freedom\n",
    "\n",
    "df = (3-1 ) * (2-1)\n",
    "print(f\"Degrees of freedom: {df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 what is the expected number of males in the age group 18-24 living in dorms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15130.580395695044"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row Total: This is the total number of people in the 18â€“24 age group (both males and females).\n",
    "# Column Total: This is the total number of males across all age groups.\n",
    "# rand Total: This is the total number of people (males and females across all age groups)\n",
    "\n",
    "# E = (Row Total * Column Total) / Grand Total\n",
    "28176 * 24998 / 46551"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 We now consider only the 18-24 year-olds. Which of the following statements is true (if relevant, in the answer options, significance level Î± = 0.05 is used)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of men: 0.49858\n",
      "95% Confidence Interval: [0.49274, 0.50442]\n"
     ]
    }
   ],
   "source": [
    "# men 14048. total 28176\n",
    "# Input data\n",
    "# Input data\n",
    "n = 28176  # Total number of individuals\n",
    "menCount = 14048  # Number of men\n",
    "\n",
    "# Calculate proportion of men\n",
    "menMean = menCount / n  # p_hat\n",
    "\n",
    "# Calculate standard error\n",
    "SE = np.sqrt(menMean * (1 - menMean) / n)\n",
    "\n",
    "# Z-critical value for 95% confidence\n",
    "z_critical = stats.t.p(0.975)  # 1 - alpha/2 for two-tailed test\n",
    "\n",
    "# Confidence interval\n",
    "margin_error = z_critical * SE\n",
    "ci = (menMean - margin_error, menMean + margin_error)\n",
    "\n",
    "# Output\n",
    "print(f\"Proportion of men: {menMean:.5f}\")\n",
    "print(f\"95% Confidence Interval: [{ci[0]:.5f}, {ci[1]:.5f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Cumulative Binominal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming independence between individuals. What is the probability, that 100 or more females\n",
    "live in a dorm with 190 people, if the probability of an individual being a female is assumed to\n",
    "be 0.45?\n",
    "\n",
    "Use the complement rule to calculate \n",
    "P(Xâ‰¥100) = 1âˆ’P(Xâ‰¤99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X >= 100) = 0.0208\n"
     ]
    }
   ],
   "source": [
    "n = 190       # Total number of trials\n",
    "p = 0.45      # Probability of success\n",
    "k = 99        # Threshold (X â‰¤ 99)\n",
    "# Complement rule: P(X >= 100) = 1 - P(X <= 99)\n",
    "probability = 1 - binom.cdf(k, n, p)\n",
    "print(f\"P(X >= 100) = {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1(15) Variance of ð¾ in the Predator-Prey Model\n",
    "non-linear error propagation rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of K: 0.000\n"
     ]
    }
   ],
   "source": [
    "# This script calculates the variance of K in the Lotka-Volterra predator-prey model using the non-linear error propagation rule.\n",
    "# How to use:\n",
    "# 1. Adjust the constants (alpha, beta, gamma, delta) and the observed values of x, y as needed.\n",
    "# 2. Ensure you update the variances (sigma_x2 and sigma_y2) for x and y based on your data.\n",
    "\n",
    "def K(x, y, alpha, beta, gamma, delta):\n",
    "    return (y**gamma) * math.exp(-beta * y) * (x**alpha) * math.exp(-delta * x)\n",
    "\n",
    "# Partial derivatives manually derived from K\n",
    "# Partial derivative w.r.t x\n",
    "def partial_x(x, y, alpha, beta, gamma, delta):\n",
    "    return (y**gamma) * math.exp(-beta * y) * (alpha * (x**(alpha - 1)) - delta * (x**alpha)) * math.exp(-delta * x)\n",
    "\n",
    "# Partial derivative w.r.t y\n",
    "def partial_y(x, y, alpha, beta, gamma, delta):\n",
    "    return (x**alpha) * math.exp(-delta * x) * (gamma * (y**(gamma - 1)) - beta * (y**gamma)) * math.exp(-beta * y)\n",
    "\n",
    "# Constants\n",
    "y = 1 / 2\n",
    "x = 1\n",
    "alpha = 2 / 3\n",
    "beta = 4 / 3\n",
    "gamma = 1\n",
    "delta = 1\n",
    "sigma_x2 = (1 / 8)**2  # Variance of x\n",
    "sigma_y2 = (1 / 16)**2  # Variance of y\n",
    "\n",
    "# Evaluate partial derivatives at given values\n",
    "partial_x_val = partial_x(x, y, alpha, beta, gamma, delta)\n",
    "partial_y_val = partial_y(x, y, alpha, beta, gamma, delta)\n",
    "\n",
    "# Apply error propagation formula\n",
    "variance_K = (partial_x_val**2 * sigma_x2) + (partial_y_val**2 * sigma_y2)\n",
    "\n",
    "print(f\"Variance of K: {variance_K:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 (17)  probability density function (PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18 Confidence interval 2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: (-50.81, -49.19)\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "mean_cheap = 1250\n",
    "mean_expensive = 1300\n",
    "std_cheap = 54.24\n",
    "std_expensive = 28.54\n",
    "n_cheap = 25000\n",
    "n_expensive = 15000\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Difference in means\n",
    "mean_diff = mean_cheap - mean_expensive\n",
    "\n",
    "# Standard error for the difference in means\n",
    "se_diff = np.sqrt((std_cheap**2 / n_cheap) + (std_expensive**2 / n_expensive))\n",
    "\n",
    "# Critical z-value for 95% confidence level\n",
    "z_critical = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "\n",
    "# Margin of error\n",
    "margin_error = z_critical * se_diff\n",
    "\n",
    "# Confidence interval\n",
    "ci_lower = mean_diff - margin_error\n",
    "ci_upper = mean_diff + margin_error\n",
    "\n",
    "print(f\"Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19 Null hypothesis Test Statistic for Difference in Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given data\n",
    "mean_cheap = 1250  # Sample mean for cheap screws\n",
    "mean_expensive = 1300  # Sample mean for expensive screws\n",
    "std_cheap = 54.24  # Sample standard deviation for cheap screws\n",
    "std_expensive = 28.54  # Sample standard deviation for expensive screws\n",
    "n_cheap = 25000  # Sample size for cheap screws\n",
    "n_expensive = 15000  # Sample size for expensive screws\n",
    "null_difference = -50  # Null hypothesis difference (H0: Î¼_cheap - Î¼_expensive = -50)\n",
    "\n",
    "# Calculate the standard error for the difference in means\n",
    "se_diff = np.sqrt((std_cheap**2 / n_cheap) + (std_expensive**2 / n_expensive))\n",
    "\n",
    "# Calculate the observed test statistic\n",
    "observed_difference = mean_cheap - mean_expensive\n",
    "test_statistic = (observed_difference - null_difference) / se_diff\n",
    "\n",
    "test_statistic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Difference: 0.053\n",
      "Standard Deviation of Differences: 0.012\n",
      "Adjusted Test Statistic: 0.786\n",
      "Adjusted P-Value: 0.452\n"
     ]
    }
   ],
   "source": [
    "log_c = np.array([7.964, 7.813, 8.299, 8.219, 9.832, 9.829, 9.842, 9.498, 7.023, 8.408])  # Current model\n",
    "log_n = np.array([7.932, 7.762, 8.243, 8.174, 9.782, 9.775, 9.794, 9.445, 6.942, 8.347])  # New model\n",
    "\n",
    "# Null hypothesis difference\n",
    "null_difference = 0.05\n",
    "\n",
    "# Step 1: Calculate the mean and standard deviation of the differences\n",
    "mean_diff = np.mean(log_c - log_n)  # Mean difference\n",
    "std_diff = np.std(log_c - log_n, ddof=1)  # Standard deviation of the differences\n",
    "\n",
    "# Step 2: Calculate the test statistic\n",
    "n = len(log_c)  # Number of paired samples\n",
    "adjusted_t_stat = (mean_diff - null_difference) / (std_diff / np.sqrt(n))  # Test statistic\n",
    "\n",
    "# Step 3: Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Step 4: Two-tailed p-value for the test statistic\n",
    "adjusted_p_value = 2 * (1 - stats.t.cdf(abs(adjusted_t_stat), df))\n",
    "\n",
    "# Output results\n",
    "print(f\"Mean Difference: {mean_diff:.3f}\")\n",
    "print(f\"Standard Deviation of Differences: {std_diff:.3f}\")\n",
    "print(f\"Adjusted Test Statistic: {adjusted_t_stat:.3f}\")\n",
    "print(f\"Adjusted P-Value: {adjusted_p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21 Reading anova summary p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.026965545909903\n",
      "P-value: 0.150669891510969\n"
     ]
    }
   ],
   "source": [
    "# 1 Is correct. pr(>f) =  0.1507\n",
    "# Since p = 0.1507 is greater than a = 0.05 we fail to reject the null hypothesis. \n",
    "# A significant breaking strength is NOT found\n",
    "# Perfomed ourselves using python EXTRA..\n",
    "# Data for ANOVA \n",
    "group1 = [92.0, 111.6, 98.4, 87.7, 134.9]\n",
    "group2 = [131.0, 103.5, 100.0, 84.7, 134.5]\n",
    "group3 = [74.1, 52.8, 82.5, 94.7, 107.3]\n",
    "group4 = [90.4, 95.2, 87.6, 63.2, 119.5]\n",
    "# Perform ANOVA\n",
    "f_stat, p_value = f_oneway(group1, group2, group3, group4)\n",
    "# Output results\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22 boxplot extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 78.00, Q3: 93.50, IQR: 15.50\n",
      "Lower Threshold: 54.75, Upper Threshold: 116.75\n",
      "Extreme Observations: []\n"
     ]
    }
   ],
   "source": [
    "# we can already there are no marked points as outliers. BUT we can also calulate it\n",
    "\n",
    "# Given data\n",
    "data = np.array([82, 70, 77, 59, 86, 81, 102, 95, 89, 104])\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "\n",
    "# Calculate IQR\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Calculate thresholds\n",
    "lower_threshold = q1 - 1.5 * iqr\n",
    "upper_threshold = q3 + 1.5 * iqr\n",
    "\n",
    "# Check for extreme observations\n",
    "extreme_observations = data[(data < lower_threshold) | (data > upper_threshold)]\n",
    "\n",
    "# Output results\n",
    "print(f\"Q1: {q1:.2f}, Q3: {q3:.2f}, IQR: {iqr:.2f}\")\n",
    "print(f\"Lower Threshold: {lower_threshold:.2f}, Upper Threshold: {upper_threshold:.2f}\")\n",
    "print(f\"Extreme Observations: {extreme_observations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23 confidence interval normal distributed population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: (63.39106927196566, 105.60893072803434)\n"
     ]
    }
   ],
   "source": [
    "# Example: mean = 75, std = 10, n = 40, alpha = 0.05\n",
    "data = np.array([82, 70, 77, 59, 86, 81, 102, 95, 89, 104])\n",
    "mean = data.mean()\n",
    "std = data.std(ddof=1)\n",
    "n = data.size\n",
    "alpha = 0.001\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "margin_error = t_critical * (std / np.sqrt(n))\n",
    "ci = (mean - margin_error, mean + margin_error)\n",
    "print(f\"Confidence Interval: {ci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24 null hypothesis one tailed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: One-sample t-test for mean = 0\n",
      "t-statistic = 1.8531, p-value = 0.09687\n",
      "Result: Fail to reject the null hypothesis (mean is not significantly different from 0).\n",
      "\n",
      "Test 2: One-sample t-test for mean > 20 (one-tailed)\n",
      "t-statistic = 1.7718, p-value (one-tailed) = 0.05510\n",
      "Result: Fail to reject the null hypothesis (mean is not significantly greater than 20).\n",
      "\n",
      "Confidence Interval for Test 2: [0.15, 905.4]\n",
      "Interpretation: 20 is within the confidence interval, so the null hypothesis is accepted.\n"
     ]
    }
   ],
   "source": [
    "# Data: Returns from the stocks\n",
    "x = np.array([1144, 1218, 1480, 747, 1178, -121, -382, -24, -652, -32])\n",
    "\n",
    "# Test 1: One-sample t-test for mean different from 0\n",
    "# Null hypothesis (H0): The mean return is 0\n",
    "t_stat1, p_val1 = ttest_1samp(x, 0)\n",
    "print(f\"Test 1: One-sample t-test for mean = 0\")\n",
    "print(f\"t-statistic = {t_stat1:.4f}, p-value = {p_val1:.5f}\")\n",
    "if p_val1 < 0.05:\n",
    "    print(\"Result: Reject the null hypothesis (mean is significantly different from 0).\\n\")\n",
    "else:\n",
    "    print(\"Result: Fail to reject the null hypothesis (mean is not significantly different from 0).\\n\")\n",
    "\n",
    "# Test 2: One-sample t-test for mean greater than 20 (one-tailed)\n",
    "# Null hypothesis (H0): The mean return is <= 20\n",
    "t_stat2, p_val2 = ttest_1samp(x, 20)\n",
    "p_val2_one_tailed = p_val2 / 2 if t_stat2 > 0 else 1  # Adjust p-value for one-tailed test\n",
    "print(f\"Test 2: One-sample t-test for mean > 20 (one-tailed)\")\n",
    "print(f\"t-statistic = {t_stat2:.4f}, p-value (one-tailed) = {p_val2_one_tailed:.5f}\")\n",
    "if p_val2_one_tailed < 0.05:\n",
    "    print(\"Result: Reject the null hypothesis (mean is significantly greater than 20).\\n\")\n",
    "else:\n",
    "    print(\"Result: Fail to reject the null hypothesis (mean is not significantly greater than 20).\\n\")\n",
    "\n",
    "# Interpretation based on confidence interval for Test 2\n",
    "ci_lower = 0.15  # Example lower bound of CI\n",
    "ci_upper = 905.4  # Example upper bound of CI\n",
    "print(f\"Confidence Interval for Test 2: [{ci_lower}, {ci_upper}]\")\n",
    "if 20 >= ci_lower and 20 <= ci_upper:\n",
    "    print(\"Interpretation: 20 is within the confidence interval, so the null hypothesis is accepted.\")\n",
    "else:\n",
    "    print(\"Interpretation: 20 is not within the confidence interval, so the null hypothesis is rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26 Calculating Residuals for a Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Lifespan: 75.31 years\n",
      "Residual: 5.99 years\n"
     ]
    }
   ],
   "source": [
    "# Given coefficients from the regression model\n",
    "intercept = 151.76054\n",
    "econ_rf_coef = -0.35638\n",
    "matr_rf_coef = -0.90717\n",
    "dsgn_rf_coef = -0.11806\n",
    "\n",
    "# Input values for the specific building\n",
    "econ_rf = 64.7  # Economical risk factor\n",
    "matr_rf = 55.2  # Material risk factor\n",
    "dsgn_rf = 28.1  # Design risk factor\n",
    "actual_lifespan = 81.3  # Observed lifespan\n",
    "\n",
    "# Predicted lifespan using the regression equation\n",
    "predicted_lifespan = (\n",
    "    intercept +\n",
    "    econ_rf_coef * econ_rf +\n",
    "    matr_rf_coef * matr_rf +\n",
    "    dsgn_rf_coef * dsgn_rf\n",
    ")\n",
    "\n",
    "# Calculate the residual\n",
    "residual = actual_lifespan - predicted_lifespan\n",
    "\n",
    "# Output the results\n",
    "print(f\"Predicted Lifespan: {predicted_lifespan:.2f} years\")\n",
    "print(f\"Residual: {residual:.2f} years\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27 Determining Total Observations from Residual Degrees of Freedom in Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Observations: 169\n"
     ]
    }
   ],
   "source": [
    "# Given values\n",
    "residual_df = 165  # Residual degrees of freedom\n",
    "predictors = 3     # Number of predictors in the model (Econ_RF, Matr_RF, Dsgn_RF)\n",
    "intercept = 1      # Intercept always counts as an additional degree of freedom\n",
    "\n",
    "# Total number of observations\n",
    "total_observations = residual_df + predictors + intercept\n",
    "\n",
    "# Output the result\n",
    "print(f\"Total Observations: {total_observations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28 which type of distrubution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29 Which type of distribution (Chi distribution with DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restul is x^2(4)\n"
     ]
    }
   ],
   "source": [
    "# We use a x^2 Chi distrubution test here. \n",
    "# As the data is categorical and not continuous. And is a table with columns and rows.\n",
    "\n",
    "# The tables have 3 rows, and 3 colums. We caclulate the decrees of freedom\n",
    "df = (3-1) * (3-1)\n",
    "print(f\"Restul is x^2({df})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
