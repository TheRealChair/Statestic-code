{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from math import exp\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for ﾏダH^2: 0.0276\n",
      "Coefficient for ﾏダR^2: 0.7518\n",
      "Variance of volume (ﾏダV^2): 0.000007 m^6\n",
      "Standard deviation of volume (ﾏダV): 0.002731 m^3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 simulation random normal distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean volume: 0.0997347994120577\n",
      "Std of volume: 0.0025879481829497353\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "mean_H, std_H = 0.6, 0.005\n",
    "mean_R, std_R = 0.23, 0.003\n",
    "pi = np.pi\n",
    "\n",
    "# Generate 1000 random heights and radii\n",
    "H_samples = np.random.normal(mean_H, std_H, 1000)\n",
    "R_samples = np.random.normal(mean_R, std_R, 1000)\n",
    "\n",
    "# Compute volumes\n",
    "volumes = H_samples * pi * (R_samples**2)\n",
    "\n",
    "# Check a few statistics\n",
    "print(\"Mean volume:\", np.mean(volumes))\n",
    "print(\"Std of volume:\", np.std(volumes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Probability of Independent Events (Binominal experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that both systems detect the attack: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Probability of one detection system identifying the attack\n",
    "p_detection = 0.90\n",
    "\n",
    "# Probability that both systems will detect the attack (independent events)\n",
    "p_both_detect = p_detection * p_detection\n",
    "\n",
    "# Output the result\n",
    "print(f\"Probability that both systems detect the attack: {p_both_detect:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Finding the Minimum Score for Top Percentile in Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum score required for grade 12: 74.69\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "mean_score = 55  # Mean score\n",
    "std_dev = 19  # Standard deviation\n",
    "top_percentage = 0.15  # Top 15%\n",
    "\n",
    "# Calculate the z-score corresponding to the 85th percentile (1 - top_percentage)\n",
    "z_score = stats.norm.ppf(1 - top_percentage)\n",
    "\n",
    "# Calculate the minimum score required for grade 12\n",
    "min_score = mean_score + z_score * std_dev\n",
    "\n",
    "# Output the result\n",
    "print(f\"Minimum score required for grade 12: {min_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Hypogeometric experiemnt (SKIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Assessing Normality for Confidence Interval Validity: Histogram, Q-Q Plot, and Large Sample Size\n",
    "read solution pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Test Statistic for Paired Sample Mean\n",
    "Read solution pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Calculating a Confidence Interval for the Mean Steps in a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% Confidence Interval: (5400, 10180)\n"
     ]
    }
   ],
   "source": [
    "# Data: Steps taken per day\n",
    "steps = np.array([8500, 10300, 6800, 10600, 4900, 6200, 10800, 5700, 5100, 9000])\n",
    "\n",
    "# Calculate sample mean and standard deviation\n",
    "mean_steps = np.mean(steps)\n",
    "std_steps = np.std(steps, ddof=1)  # Use ddof=1 for sample standard deviation\n",
    "n = len(steps)  # Sample size\n",
    "\n",
    "# Confidence level and t-critical value\n",
    "confidence_level = 0.99\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)  # t-critical value for 99% confidence\n",
    "\n",
    "# Margin of error\n",
    "margin_of_error = t_critical * (std_steps / np.sqrt(n))\n",
    "\n",
    "# Confidence interval\n",
    "lower_bound = mean_steps - margin_of_error\n",
    "upper_bound = mean_steps + margin_of_error\n",
    "\n",
    "print(f\"99% Confidence Interval: ({lower_bound:.0f}, {upper_bound:.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 Testing a Hypothesis for a Single Sample Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -3.0047\n",
      "P-value: 0.01484\n",
      "The null hypothesis is rejected, since the p-value is below 5%.\n"
     ]
    }
   ],
   "source": [
    "# Data: Steps taken per day\n",
    "steps = np.array([8500, 10300, 6800, 10600, 4900, 6200, 10800, 5700, 5100, 9000])\n",
    "\n",
    "# Hypothesized population mean\n",
    "mu_0 = 10000\n",
    "\n",
    "# Perform one-sample t-test\n",
    "t_stat, p_value = ttest_1samp(steps, mu_0)\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Decision\n",
    "if p_value < alpha:\n",
    "    conclusion = \"The null hypothesis is rejected, since the p-value is below 5%.\"\n",
    "else:\n",
    "    conclusion = \"The null hypothesis is not rejected, since the p-value is above 5%.\"\n",
    "\n",
    "# Output results\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.5f}\")\n",
    "print(conclusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
